{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48330b27-410b-41a2-9f82-6d3440cc3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa307f1-6715-4b4d-be23-be992a328a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_000.csv: unexpected end of data\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_001.csv: unexpected end of data\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_002.csv: unexpected end of data\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_003.csv: ',' expected after '\"'\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_005.csv: unexpected end of data\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_006.csv: ',' expected after '\"'\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_007.csv: Expected 2 fields in line 330, saw 3\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_010.csv: unexpected end of data\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_012.csv: unexpected end of data\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_013.csv: ',' expected after '\"'\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_014.csv: ',' expected after '\"'\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_017.csv: unexpected end of data\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_018.csv: ',' expected after '\"'\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_020.csv: unexpected end of data\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_021.csv: ',' expected after '\"'\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_022.csv: unexpected end of data\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_023.csv: Expected 3 fields in line 153, saw 4\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_025.csv: unexpected end of data\n",
      "Error reading Data/Train/fulltrain_Guardian_Nyt_binary_shuffled_026.csv: ',' expected after '\"'\n",
      "Training dataset shape: (28633, 2)\n",
      "Testing dataset shape: (7011, 2)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 (Modified): Load the Datasets and Fix Test Column Order\n",
    "import csv\n",
    "\n",
    "train_files = glob.glob(os.path.join(\"Data\", \"Train\", \"*.csv\"))\n",
    "test_files = glob.glob(os.path.join(\"Data\", \"Test\", \"*.csv\"))\n",
    "\n",
    "if len(train_files) == 0:\n",
    "    raise FileNotFoundError(\"No training CSV files found in Data/Train\")\n",
    "if len(test_files) == 0:\n",
    "    raise FileNotFoundError(\"No testing CSV files found in Data/Test\")\n",
    "\n",
    "# Read training files (using default CSV settings)\n",
    "train_dfs = []\n",
    "for file in train_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file, engine='python')\n",
    "        train_dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "train_df = pd.concat(train_dfs, ignore_index=True)\n",
    "\n",
    "# Read testing files\n",
    "test_dfs = []\n",
    "for file in test_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file, engine='python')\n",
    "        test_dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "test_df = pd.concat(test_dfs, ignore_index=True)\n",
    "\n",
    "# Fix test_df column order if necessary.\n",
    "# If the first column is \"Label\", then reorder to have \"Statement\" first.\n",
    "if test_df.columns[0].strip().lower() == \"label\":\n",
    "    test_df = test_df[[\"Statement\", \"Label\"]]\n",
    "\n",
    "print(\"Training dataset shape:\", train_df.shape)\n",
    "print(\"Testing dataset shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bba1e7cd-e2d0-487e-a84b-8215f723ab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Training dataset shape: (28633, 2)\n",
      "Processed Testing dataset shape: (7011, 2)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 (Modified): Handle Missing Values Precisely\n",
    "# Drop rows where the 'Statement' column is empty after stripping whitespace.\n",
    "train_df = train_df[train_df[\"Statement\"].astype(str).str.strip() != \"\"]\n",
    "test_df = test_df[test_df[\"Statement\"].astype(str).str.strip() != \"\"]\n",
    "\n",
    "print(\"Processed Training dataset shape:\", train_df.shape)\n",
    "print(\"Processed Testing dataset shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d40631b-7d76-4d96-8e64-b43e4cd28ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example training statement: Sainsburyâ€™s sales have dropped further after it was forced to cut prices amid heavy competition from discount rivals. Sales at stores open for more than a year fell by 1.1% in the three months to 24 September, compared with the 0.8% decline reported for the previous three months. Shares in Sainsburyâ€™s slid 3.5% to 242.2p in morning trading, as City analysts said the supermarket had slightly underperformed against expectations and appeared to be under more pressure in comparison with Morrisons and Tesco. Mike Coupe, Sainsburyâ€™s chief executive, said the fall in sales was driven by price cuts. Although a 1% dip in prices resulted in a drop in the total value of Sainsburyâ€™s sales in the quarter, the reductions drew more people to Sainsburyâ€™s tills and meant the group sold a higher volume of goods. Coupe said there had been no discernible impact on customer behaviour after the EU referendum, and he thought there would not be any impact on shopping unless and until the UKâ€™s step away from the union started to â€œinterfere with or influence peopleâ€™s day-to-day livesâ€.   Related: UK supermarket sales suffer worst fall for at least two years   â€œWe expect the market to remain competitive and the effect of the devaluation of sterling remains unclear,â€ Coupe added. â€œHowever, Sainsburyâ€™s is well positioned to navigate the changing marketplace and we are confident that our strategy will enable us to continue to outperform our major peers.â€  He said Sainsburyâ€™s would continue to make â€œtargeted investmentsâ€ in lowering prices, and had recently cut the price of nappies by 36% and broccoli by 20%. The chief executive said food prices might continue to fall as a result of strong harvests in northern Europe and a drop in the price of oil. But he said there were other inflationary pressures, including a drop in the value of the pound against the dollar and the euro, and a drought in Brazil that had raised the price of coffee. While food sales fell, Sainsburyâ€™s performance was lifted by a 4% increase in general merchandise sales. But the supermarket admitted that its clothing sales had decreased slightly, despite the launch of Tu Premium, a more upmarket version of the Tu brand. Coupe said Sainsburyâ€™s first ever quarterly fall in clothing sales had come as a number of other retailers, including Marks & Spencer and Primark, also reported falls after unseasonably cool weather in June and warm weather in September.   Related: Sainsbury's one-hour delivery service takes on Amazon   â€œRelative to the competition, we have done well,â€ he said. â€œClothing has probably been our most challenging area during the course of the last quarter.â€ Sales at Argos, which Sainsburyâ€™s took control of three weeks ago, rose 2.3% at stores open more than a year in the three months to 27 August, its best performance since 2014. It was a big step up in pace from the 0.1% reported for the previous quarter â€“ Argosâ€™s first quarter of growth in more than a year.  Sainsburyâ€™s said it was not able to provide detail on how Argosâ€™s sales had improved so dramatically and Coupe said his view of the merger had not changed. â€œI have never not been confident about the deal. Customersâ€™ habits are changing, shopping habits are changing very rapidly, driven by the rise of digital. Customers demand more utility and more speed, and Argos gives us the ability to serve customers in an increasingly rapidly changing world,â€ Coupe said. Sainsburyâ€™s convenience store sales rose by 7% over the quarter as it opened nine new outlets, while online sales were up by 8%.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 (Modified): Extract Features and Labels\n",
    "X_train = train_df[\"Statement\"]\n",
    "y_train = train_df[\"Label\"]\n",
    "\n",
    "X_test = test_df[\"Statement\"]\n",
    "y_test = test_df[\"Label\"]\n",
    "\n",
    "# (Optional) Print an example to verify the content:\n",
    "print(\"Example training statement:\", X_train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3936af-b99b-4405-adeb-3ade87256eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4.1: Clean and Shuffle the Data\n",
    "# Keep only binary labels (0 or 1)\n",
    "train_df = train_df[train_df['Label'].isin([0, 1])]\n",
    "test_df = test_df[test_df['Label'].isin([0, 1])]\n",
    "\n",
    "# Convert the Label columns to integers to ensure numeric type.\n",
    "train_df['Label'] = train_df['Label'].astype(int)\n",
    "test_df['Label'] = test_df['Label'].astype(int)\n",
    "\n",
    "# Shuffle the data\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Re-extract features and labels after cleaning\n",
    "X_train = train_df['Statement']\n",
    "y_train = train_df['Label']\n",
    "X_test = test_df['Statement']\n",
    "y_test = test_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f81bc4-7479-44dc-bb5d-b95e142cc953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Preprocess Text for the LSTM\n",
    "def tokenize(text):\n",
    "    # Convert text to lowercase and extract word tokens.\n",
    "    text = text.lower()\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text)\n",
    "    return tokens\n",
    "\n",
    "# Build vocabulary from the training statements.\n",
    "all_tokens = []\n",
    "for text in X_train:\n",
    "    all_tokens.extend(tokenize(text))\n",
    "    \n",
    "# Limit vocabulary to the 10,000 most common words.\n",
    "max_vocab = 10000\n",
    "freq = Counter(all_tokens)\n",
    "vocab = {word: i+2 for i, (word, count) in enumerate(freq.most_common(max_vocab))}\n",
    "vocab_size = len(vocab) + 2  # Add 2 for reserved tokens: 0 for padding, 1 for unknown.\n",
    "\n",
    "def text_to_sequence(text, vocab):\n",
    "    tokens = tokenize(text)\n",
    "    return [vocab.get(token, 1) for token in tokens]\n",
    "\n",
    "# Convert texts to sequences of token indices.\n",
    "X_train_seq = [text_to_sequence(text, vocab) for text in X_train]\n",
    "X_test_seq = [text_to_sequence(text, vocab) for text in X_test]\n",
    "\n",
    "# Set fixed maximum sequence length.\n",
    "max_len = 300\n",
    "\n",
    "def pad_sequence(seq, max_len):\n",
    "    if len(seq) < max_len:\n",
    "        return seq + [0] * (max_len - len(seq))\n",
    "    else:\n",
    "        return seq[:max_len]\n",
    "\n",
    "# Apply padding/truncation.\n",
    "X_train_pad = [pad_sequence(seq, max_len) for seq in X_train_seq]\n",
    "X_test_pad = [pad_sequence(seq, max_len) for seq in X_test_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94eb5946-b06a-40f5-8823-972f6e32eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Convert Sequences to Torch Tensors\n",
    "X_train_tensor = torch.tensor(X_train_pad, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_pad, dtype=torch.long)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e539c447-9a60-4872-bed9-8f3b4616ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create a PyTorch Dataset and DataLoader\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = NewsDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = NewsDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5198ec2-8fd5-48cb-a33d-602885bd8ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (embedding): Embedding(10002, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8: Define the LSTM Model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_hidden = lstm_out[:, -1, :]\n",
    "        return self.fc(last_hidden)\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "output_dim = 2  # Adjust if you have a different number of classes\n",
    "\n",
    "model = LSTMClassifier(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Set the device (using 'cuda:2' if available, otherwise CPU)\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d19deb77-cf6f-4e50-b5b2-8f2995898d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9 - Loss: 0.4892 - Accuracy: 0.7623\n",
      "Epoch 2/9 - Loss: 0.1951 - Accuracy: 0.9225\n",
      "Epoch 3/9 - Loss: 0.1050 - Accuracy: 0.9621\n",
      "Epoch 4/9 - Loss: 0.0613 - Accuracy: 0.9784\n",
      "Epoch 5/9 - Loss: 0.0410 - Accuracy: 0.9857\n",
      "Epoch 6/9 - Loss: 0.0250 - Accuracy: 0.9920\n",
      "Epoch 7/9 - Loss: 0.0190 - Accuracy: 0.9941\n",
      "Epoch 8/9 - Loss: 0.0116 - Accuracy: 0.9966\n",
      "Epoch 9/9 - Loss: 0.0126 - Accuracy: 0.9965\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Train the Model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 8\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for texts, labels in train_loader:\n",
    "        texts = texts.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * texts.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8b33374-d198-4838-9f92-a7c5bd388855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test Accuracy: 0.9596348595064899\n",
      "LSTM Test Precision: 0.9596772338446422\n",
      "LSTM Test Recall: 0.9596348595064899\n",
      "LSTM Test F1-Score: 0.9593333390442632\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Evaluate the Model\n",
    "if y_test is not None:\n",
    "    model.eval()  \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for texts, labels in test_loader:\n",
    "            texts = texts.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(texts)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, average='weighted')\n",
    "    rec = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(\"LSTM Test Accuracy:\", acc)\n",
    "    print(\"LSTM Test Precision:\", prec)\n",
    "    print(\"LSTM Test Recall:\", rec)\n",
    "    print(\"LSTM Test F1-Score:\", f1)\n",
    "else:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test_tensor.to(device))\n",
    "        _, predicted = torch.max(predictions, 1)\n",
    "    print(\"Sample predictions on test data:\", predicted.cpu().numpy()[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env1)",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
