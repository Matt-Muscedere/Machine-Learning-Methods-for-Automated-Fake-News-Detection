{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71208521-3954-49b4-b87d-8dd68825d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019d9361-4905-4b10-94b7-703411bdfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the Datasets\n",
    "# Load the Kaggle dataset\n",
    "kaggle_df = pd.read_csv('Data/Data.csv')\n",
    "\n",
    "# Load the ISOT datasets\n",
    "true_df = pd.read_csv('Data/True.csv')\n",
    "fake_df = pd.read_csv('Data/Fake.csv')\n",
    "\n",
    "# For ISOT, assign labels: assume true news = 1 and fake news = 0\n",
    "true_df['label'] = 1\n",
    "fake_df['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f239d3-504f-43d7-84e0-b06fb4e604ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle dataset shape: (20800, 5)\n",
      "ISOT dataset shape: (44898, 5)\n",
      "Combined dataset shape: (65698, 7)\n"
     ]
    }
   ],
   "source": [
    "# 3. Combine the Datasets\n",
    "# Combine the two ISOT datasets\n",
    "isot_df = pd.concat([true_df, fake_df], ignore_index=True)\n",
    "\n",
    "# Optionally, inspect shapes\n",
    "print(\"Kaggle dataset shape:\", kaggle_df.shape)\n",
    "print(\"ISOT dataset shape:\", isot_df.shape)\n",
    "\n",
    "# Combine Kaggle and ISOT data into one DataFrame\n",
    "df = pd.concat([kaggle_df, isot_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Combined dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d20b9f0-87c5-4f9a-8076-d095f06fce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Handle Missing Values\n",
    "# Drop rows missing 'text' (critical for classification)\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "# Fill missing 'title' values with a placeholder\n",
    "df['title'] = df['title'].fillna(\"No Title Provided\")\n",
    "\n",
    "# If there is an 'author' column, fill missing values with \"Unknown\"\n",
    "if 'author' in df.columns:\n",
    "    df['author'] = df['author'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc44d144-d471-48b3-8b4f-d75201b6e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create the 'content' Column\n",
    "# Combine 'title' and 'text' into a single text field\n",
    "if 'content' not in df.columns:\n",
    "    df['content'] = df['title'] + \" \" + df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9d5ddc-cf55-47ce-a334-5ca6ccb87e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Split into Training and Testing Sets\n",
    "X = df['content']\n",
    "y = df['label']\n",
    "\n",
    "# Split the data (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86077f53-1f35-4c12-9994-557155e9eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Preprocess Text for the LSTM (Updated)\n",
    "def tokenize(text):\n",
    "    # Convert to lowercase and split by word boundaries\n",
    "    text = text.lower()\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text)\n",
    "    return tokens\n",
    "\n",
    "# Build vocabulary from training texts, limiting to the top 10,000 words\n",
    "all_tokens = []\n",
    "for text in X_train:\n",
    "    all_tokens.extend(tokenize(text))\n",
    "\n",
    "freq = Counter(all_tokens)\n",
    "max_vocab = 10000  # Limit vocabulary size to 10,000 words\n",
    "vocab = {word: i+2 for i, (word, count) in enumerate(freq.most_common(max_vocab))}\n",
    "vocab_size = len(vocab) + 2  # Reserve indices 0 for padding and 1 for unknown tokens\n",
    "\n",
    "def text_to_sequence(text, vocab):\n",
    "    tokens = tokenize(text)\n",
    "    return [vocab.get(token, 1) for token in tokens]  # 1 for unknown words\n",
    "\n",
    "# Convert texts to sequences of token indices\n",
    "X_train_seq = [text_to_sequence(text, vocab) for text in X_train]\n",
    "X_test_seq = [text_to_sequence(text, vocab) for text in X_test]\n",
    "\n",
    "# Pad sequences to a fixed length (reduce max_len to lessen memory load)\n",
    "max_len = 300  # Reduced from 500\n",
    "def pad_sequence(seq, max_len):\n",
    "    if len(seq) < max_len:\n",
    "        return seq + [0] * (max_len - len(seq))\n",
    "    else:\n",
    "        return seq[:max_len]\n",
    "\n",
    "X_train_pad = [pad_sequence(seq, max_len) for seq in X_train_seq]\n",
    "X_test_pad = [pad_sequence(seq, max_len) for seq in X_test_seq]\n",
    "\n",
    "# Convert padded sequences and labels to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train_pad, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_pad, dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2397f13f-e143-42cf-895d-d5c1d8ebc543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Create a PyTorch Dataset and DataLoader (Updated)\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "batch_size = 16  # Reduced batch size to lower memory usage\n",
    "train_dataset = NewsDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = NewsDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05fc0ca9-236b-46c5-a4ec-b9c8075a3341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New train set size: 42022, Validation set size: 10505\n"
     ]
    }
   ],
   "source": [
    "# 8.1 Create a validation split from the training dataset\n",
    "\n",
    "# Assume train_dataset is already defined (from your original Cell 8)\n",
    "# Split train_dataset into training and validation subsets (e.g., 80% train, 20% validation)\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "total_train = len(train_dataset)\n",
    "val_size = int(0.2 * total_train)\n",
    "train_size = total_train - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader for the validation set\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"New train set size: {len(train_dataset)}, Validation set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f8b5cb-a710-4317-b79a-bfabb77b9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_sequence(seq, drop_prob=0.1):\n",
    "    # For each token in the sequence (except padding tokens, which are 0),\n",
    "    # with probability drop_prob, replace the token with 1 (the unknown token).\n",
    "    augmented = [token if token == 0 or np.random.rand() > drop_prob else 1 for token in seq]\n",
    "    return augmented\n",
    "\n",
    "# Update your NewsDataset to support augmentation.\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, augment=False, drop_prob=0.1):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.augment = augment\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the text tensor for the given index.\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.augment:\n",
    "            # Convert tensor to list, augment, and convert back.\n",
    "            text_list = text.tolist()\n",
    "            text_list = augment_sequence(text_list, drop_prob=self.drop_prob)\n",
    "            text = torch.tensor(text_list, dtype=torch.long)\n",
    "        return text, label\n",
    "\n",
    "# When creating your training dataset, enable augmentation:\n",
    "train_dataset = NewsDataset(X_train_tensor, y_train_tensor, augment=True, drop_prob=0.1)\n",
    "# For validation and test sets, do not augment:\n",
    "val_dataset = NewsDataset(X_test_tensor, y_test_tensor, augment=False)\n",
    "# (If you already have a validation split from Cell 8.1, use that dataset for validation without augmentation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19f54e24-a93a-4ad7-a1b5-c830724f4a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder Pretrain Epoch 1/10 - Loss: 0.6030\n",
      "Autoencoder Pretrain Epoch 2/10 - Loss: 0.0020\n",
      "Autoencoder Pretrain Epoch 3/10 - Loss: 0.0003\n",
      "Autoencoder Pretrain Epoch 4/10 - Loss: 0.0001\n",
      "Autoencoder Pretrain Epoch 5/10 - Loss: 0.0000\n",
      "Autoencoder Pretrain Epoch 6/10 - Loss: 0.0000\n",
      "Autoencoder Pretrain Epoch 7/10 - Loss: 0.0000\n",
      "Autoencoder Pretrain Epoch 8/10 - Loss: 0.0000\n",
      "Autoencoder Pretrain Epoch 9/10 - Loss: 0.0000\n",
      "Autoencoder Pretrain Epoch 10/10 - Loss: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9: Pretrain the LSTM Autoencoder\n",
    "\n",
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, latent_dim):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc_enc = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_dec = nn.Linear(latent_dim, embedding_dim)\n",
    "        self.decoder = nn.LSTM(embedding_dim, embedding_dim, batch_first=True)\n",
    "        self.output_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # [batch, seq_length, embedding_dim]\n",
    "        _, (hidden, _) = self.encoder(embedded)  # hidden: [num_layers, batch, hidden_dim]\n",
    "        latent = self.fc_enc(hidden[-1])  # [batch, latent_dim]\n",
    "        hidden_dec = self.fc_dec(latent).unsqueeze(0)  # [1, batch, embedding_dim]\n",
    "        cell_dec = torch.zeros_like(hidden_dec)\n",
    "        dec_out, _ = self.decoder(embedded, (hidden_dec, cell_dec))\n",
    "        reconstructed = self.output_layer(dec_out)  # [batch, seq_length, vocab_size]\n",
    "        return latent, reconstructed\n",
    "\n",
    "# Hyperparameters for pretraining\n",
    "pretrain_epochs = 10\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "latent_dim = 64\n",
    "\n",
    "autoencoder = LSTMAutoencoder(vocab_size, embedding_dim, hidden_dim, latent_dim)\n",
    "autoencoder.to(device)\n",
    "\n",
    "criterion_recon = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer_ae = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "best_recon_loss = float('inf')\n",
    "for epoch in range(pretrain_epochs):\n",
    "    autoencoder.train()\n",
    "    running_loss = 0.0\n",
    "    for texts, _ in train_loader:  # Using only texts; labels are not used here.\n",
    "        texts = texts.to(device)\n",
    "        optimizer_ae.zero_grad()\n",
    "        _, reconstructed = autoencoder(texts)\n",
    "        loss = criterion_recon(reconstructed.view(-1, vocab_size), texts.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer_ae.step()\n",
    "        running_loss += loss.item() * texts.size(0)\n",
    "    avg_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Autoencoder Pretrain Epoch {epoch+1}/{pretrain_epochs} - Loss: {avg_loss:.4f}\")\n",
    "    if avg_loss < best_recon_loss:\n",
    "        best_recon_loss = avg_loss\n",
    "        best_autoencoder_state = autoencoder.state_dict()\n",
    "\n",
    "# Optionally load the best state\n",
    "autoencoder.load_state_dict(best_autoencoder_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30146771-ed1e-405e-a9b3-5c34630097dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Define the Joint LSTM Autoencoder-Classifier Model with Increased Latent Dimension and Dropout\n",
    "class JointLSTMAutoencoderClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, latent_dim, output_dim):\n",
    "        super(JointLSTMAutoencoderClassifier, self).__init__()\n",
    "        # Shared embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # Encoder: LSTM to encode the input into a latent representation\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc_enc = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder: reconstruct the input from the latent vector\n",
    "        self.fc_dec = nn.Linear(latent_dim, embedding_dim)\n",
    "        self.decoder = nn.LSTM(embedding_dim, embedding_dim, batch_first=True)\n",
    "        self.output_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "        # Classifier head with dropout regularization\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Added dropout here\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_length]\n",
    "        embedded = self.embedding(x)  # [batch, seq_length, embedding_dim]\n",
    "        _, (hidden, _) = self.encoder(embedded)  # hidden: [num_layers, batch, hidden_dim]\n",
    "        latent = self.fc_enc(hidden[-1])         # [batch, latent_dim]\n",
    "        \n",
    "        # Classification output from latent representation\n",
    "        class_output = self.classifier(latent)     # [batch, output_dim]\n",
    "        \n",
    "        # Reconstruction branch\n",
    "        hidden_dec = self.fc_dec(latent).unsqueeze(0)  # [1, batch, embedding_dim]\n",
    "        cell_dec = torch.zeros_like(hidden_dec)\n",
    "        dec_out, _ = self.decoder(embedded, (hidden_dec, cell_dec))\n",
    "        reconstructed = self.output_layer(dec_out)     # [batch, seq_length, vocab_size]\n",
    "        \n",
    "        return latent, reconstructed, class_output\n",
    "\n",
    "# Increase latent dimension from 64 to 128\n",
    "latent_dim = 128\n",
    "\n",
    "# (Ensure that vocab_size, embedding_dim, hidden_dim, and output_dim have been defined.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc0269-dad4-44bb-b77d-b574e8a3e93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 1.0218 - Train Acc: 0.5556 - Alpha: 0.5000\n",
      "Validation Loss: 0.6796 - Validation Acc: 0.5772\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Twoâ€‘Phase Joint Training with Validation, Early Stopping, and Alpha Scheduling\n",
    "\n",
    "# Set device and hyperparameters (make sure these are defined earlier if needed)\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedding_dim = 100   # as before\n",
    "hidden_dim = 128      # as before\n",
    "# latent_dim is now 128 (set above)\n",
    "output_dim = 2        # binary classification\n",
    "\n",
    "# Instantiate the joint model\n",
    "joint_model = JointLSTMAutoencoderClassifier(vocab_size, embedding_dim, hidden_dim, latent_dim, output_dim)\n",
    "joint_model.to(device)\n",
    "\n",
    "# For this experiment, we will not load a pretrained autoencoder from an extra file.\n",
    "# Instead, we train the joint model from scratch in two phases.\n",
    "\n",
    "# Phase 1: Freeze the encoder (and optionally the embedding layer) and train only the classifier head.\n",
    "for param in joint_model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "joint_model.embedding.weight.requires_grad = False  # Freeze embeddings too\n",
    "\n",
    "criterion_recon = nn.CrossEntropyLoss(ignore_index=0)  # Reconstruction loss\n",
    "criterion_cls = nn.CrossEntropyLoss()                  # Classification loss\n",
    "optimizer_joint = optim.Adam(joint_model.parameters(), lr=0.001)\n",
    "\n",
    "patience = 3\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "phase1_epochs = 5  # Train classifier head with frozen encoder\n",
    "phase2_epochs = 5  # Fine-tune the entire network\n",
    "initial_alpha = 0.5  # Starting weight for classification loss\n",
    "\n",
    "# Lists to store metrics for plotting\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "total_epochs = phase1_epochs + phase2_epochs\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    # In Phase 2, unfreeze the encoder and embeddings\n",
    "    if epoch == phase1_epochs:\n",
    "        print(\"Unfreezing encoder and embedding layer for Phase 2...\")\n",
    "        for param in joint_model.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "        joint_model.embedding.weight.requires_grad = True\n",
    "    \n",
    "    # Adjust alpha with a decay schedule (example: 10% decay per epoch)\n",
    "    current_alpha = initial_alpha * (0.9 ** epoch)\n",
    "    \n",
    "    joint_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for texts, labels in train_loader:\n",
    "        texts = texts.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer_joint.zero_grad()\n",
    "        latent, reconstructed, class_output = joint_model(texts)\n",
    "        \n",
    "        loss_recon = criterion_recon(reconstructed.view(-1, vocab_size), texts.view(-1))\n",
    "        loss_cls = criterion_cls(class_output, labels)\n",
    "        loss = loss_recon + current_alpha * loss_cls\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_joint.step()\n",
    "        \n",
    "        running_loss += loss.item() * texts.size(0)\n",
    "        _, predicted = torch.max(class_output, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / total_train\n",
    "    train_acc = correct_train / total_train\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    print(f\"Epoch {epoch+1}/{total_epochs} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f} - Alpha: {current_alpha:.4f}\")\n",
    "    \n",
    "    # Evaluate on validation set (using val_loader from Cell 8.1)\n",
    "    joint_model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in val_loader:\n",
    "            texts = texts.to(device)\n",
    "            labels = labels.to(device)\n",
    "            _, _, class_output = joint_model(texts)\n",
    "            loss_val = criterion_cls(class_output, labels)\n",
    "            val_loss += loss_val.item() * texts.size(0)\n",
    "            _, predicted_val = torch.max(class_output, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted_val == labels).sum().item()\n",
    "    \n",
    "    avg_val_loss = val_loss / total_val\n",
    "    val_acc = correct_val / total_val\n",
    "    val_loss_list.append(avg_val_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f} - Validation Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        best_model_state = joint_model.state_dict()\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20520b97-c77f-4399-8587-4b52a4079730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Plot Metrics and Evaluate on Test Set\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_range = range(1, len(train_loss_list) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_loss_list, label='Train Loss')\n",
    "plt.plot(epochs_range, val_loss_list, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_acc_list, label='Train Accuracy')\n",
    "plt.plot(epochs_range, val_acc_list, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "joint_model.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for texts, labels in test_loader:\n",
    "        texts = texts.to(device)\n",
    "        labels = labels.to(device)\n",
    "        _, _, class_output = joint_model(texts)\n",
    "        _, predicted = torch.max(class_output, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = correct_test / total_test\n",
    "print(\"Joint Model Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e23823-f090-4c33-a49b-2828c3bbac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Plot Metrics and Evaluate on Test Set\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_range = range(1, len(train_loss_list) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_loss_list, label='Train Loss')\n",
    "plt.plot(epochs_range, val_loss_list, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_acc_list, label='Train Accuracy')\n",
    "plt.plot(epochs_range, val_acc_list, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "joint_model.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for texts, labels in test_loader:\n",
    "        texts = texts.to(device)\n",
    "        labels = labels.to(device)\n",
    "        _, _, class_output = joint_model(texts)\n",
    "        _, predicted = torch.max(class_output, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = correct_test / total_test\n",
    "print(\"Joint Model Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env1)",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
